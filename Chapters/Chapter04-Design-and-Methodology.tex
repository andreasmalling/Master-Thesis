\chapter{Design and Methodology}
\label{cha:design-and-method}

\section{Video content and encoding}
\label{sec:video-encoding}

\subsection{Video quality metrics}
\url{http://videoclarity.com/wpunderstandingjnddmospsnr/}. 

\subsubsection{\ac{MOS}}
MOS is a user evaluated score, that ranges from 1 to 5 used to define the quality of video. MOS can be estimated through mathematical analysis, where there are multiple approaches either using a reference where no errors occur (input) and compare it to a video with lost frames (output). Other approaches only analyze output.\\
There are two ways that can lead to error when viewing digital video:
\begin{enumerate}
    \item Errors in the digital transmission path, meaning loss or picture and or audio.
    \item The video is compressed too much, leading to a noticeable quality loss.
\end{enumerate}

\subsubsection{Frame types}
Many video codecs use a group of pictures frame structure, which consists of 3 types of frames.

\begin{itemize}
    \item I frames: independently coded reference frame.
    \item P frames: motion changes dependent from last frame.
    \item B frames: motion changes from last or next reference I frame.
\end{itemize}

Depending on which frame is lost in network traffic, impacts of how many frames are affected vary, i.e. losing an I frame causes all frames until next I frame to lose quality, but losing a P frame only affects all frames until the next I frame. losing a B frame only affects that single frame as no other frame is dependent on it.\\
These errors are attempted to be concealed during decoding, the portions of the screen where this is done stay in place until the next I frame or motion changes on that segment of the screen. Videos can also require a re-compression in order to fit into the available bandwidth in which case the image can become blocky or blurry if the compression is too high.

\subsubsection{Error metrics}
PSNR (peak singal-to-noise ratio) MSE (mean squared error) both compare processed input to an unprocessed

\subsection{DASHing}
Splitting up videos allows for easier \acs{IPFS} sharing. The file segmentation is important to enforce the flow of downloaded files through IPFS, due to a request queue of segments generated by the DASH client.

This is possible due to the DASH live profile, which support multiple files (segments) to form a stream. As a consequence of the segmentation each file should begin with an I-Frame, which could mean that a video needs to be re-encoded to have enough "possible split-points".

Though DASH is designed for multiple streams of different bit rate and a adaptive behaviour to maximize the quality of the downloaded content, this aspect won't be examined. Due to the back-end being \acs{P2P}, a single stream of video and audio is chosen to maximize availability of these files. As part of the hypothesis, it is also expected that a single high quality source on IPFS can be served equally satisfactorily as several streams in a centralized setup.

\subsection{Multimedia Container \& Codecs}
The chosen format for the stream is selected from the DASH-AVC/264 standard\cite{dash264}, due to its interoperability and because it's supported by the \texttt{dash.js} player.
The standard defines the multimedia container as MP4, the video codec as H.264 and the audio codec as AAC. As a addition separate audio and video streams are required, which means that multiplexing isn't allowed.



\section{Personas}
Possible user behaviours can be used in the experiment, they wary between collective and individual behaviours.\\
Collective behaviours affect the entire network and how the video is watched over time.
\subsection{Collective behaviours}
\begin{itemize}
    \item Social:
    Videos accessed through direct link (shared socially). Candidates for becoming viral, these videos tend to peak in views and then fall of drastically
    \item Non-social:
    Videos found through searching or related videos internally on site, these videos have more stable views over time in comparison to social.
\end{itemize}

\subsection{Individual behaviours}
Behaviours can also vary depending on the individual user, the following are possible different kinds of users that could use the system.
\begin{itemize}
    \item Seeder:
    Is the user that is sharing content, either being the origin poster of said content or re-hosting it after having watched it themselves.
    \item Leecher:
    Is a user that tries to exploit the system, by minimizing the content shared with the other peers %use a different peer as gateway, maybe bootstrap
    \item Mobile User:
    Is a user similar to the seeder, but is more unreliable due to fluctuating network connections
    \item Binge:
    Is a user that watches all content in chronological order
    \item Skipper:
    Is a user that watches many small segments of the video, by watching a small segment and then skipping forwards to watch another small segment.
    \item Incognito:
    Is a user only available in the network for a short time, watching a single video (or part of video) and deletes all of their content afterwards
\end{itemize}

\section{Evaluation Experiments}
Experiments for measuring \ac{QOE}, meaning no re-buffering and stalls of streams;
\begin{itemize}
    \item \textbf{Bandwidth:}
    Both the upload and download speeds of the client can be manipulated, and at which point does these become to low to get a pleasant viewing experience, meaning that the video does not halt after it has initially started. Also how does the low upload affect the other peers, and what innfluence does fluctuating bandwidth capacity have such as that of a mobile client.
    \textit{Cases of eg. mobile devices.}
    \item \textbf{Churn rate:}
    What effect does clients leaving the network have on the video, and can videos partially or entirely disappear from the network, can a video be popular enough that this cannot reasonably occur. IT makes sense to see influence, due to the novelty of IPFS.
    \item \textbf{Segments availability:}
    What impact does the popularity of the video have in terms of availability
    \textit{Cases of spike in users, unpopular video performance. }
    \item \textbf{Video Quality:}
    Influence of resolution, \acs{FPS}, I-Frame interval, bit rate as in \cite{aloman2015performance}.
    \item \textbf{Buffer size:}
    Influence of changing DASH preferred buffer size. %Done dynamically already, so maybe not that interesting. 
    \item \textbf{Public IPFS:}
    How does IPFS perform in a small environment dedicated only to running the tests versus running the test in the global IPFS network that is also used for other unrelated services.
    \textit{Case of "in the wild" performance.} 
\end{itemize}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../ClassicThesis"
%%% End:
