\chapter{Design and Methodology}
\label{cha:design-and-method}

\colorbox{yellow}{\textbf{TODO:} Add some kind of introduction.}


\section{Video quality metrics}
The following describes how the quality of a video can be defined objectively and perceptually.

\subsection{Frame types}
The images of a video is constructed from a series of pictures called frames, many video codecs use a group of pictures frame structure, which consists of 3 types of frames.

a program or device used for encoding or decoding audio and/or video

\begin{itemize}
    \item I frames: independently coded reference frame.
    \item P frames: motion changes dependent from last frame.
    \item B frames: motion changes from last or next reference I frame.
\end{itemize}

Depending on which frame is lost in network traffic, impacts of how many frames are affected vary, i.e. losing an I frame causes all frames until next I frame to lose quality, but losing a P frame only affects all frames until the next I frame. losing a B frame only affects that single frame as no other frame is dependent on it.\\
These errors are attempted to be concealed during decoding, the portions of the screen where this is done stay in place until the next I frame or motion changes on that segment of the screen. Videos can also require a re-compression in order to fit into the available bandwidth in which case the image can become blocky or blurry if the compression is too high.
Since I frames contains information on all pixels in the frame, they are always the biggest of the 3 types. Increasing the number of I frames results in fewer prediction errors, but increases the bit-rate due to their size.


\subsection{\acl{MOS}}
\ac{MOS} is a user evaluated score, that ranges from 1 to 5 used to define the quality of video. \ac{MOS} can be estimated through mathematical analysis, where there are multiple approaches either using a reference where no errors occur (input) and compare it to a video with lost frames (output). Other approaches only analyze output.\\
There are two ways that can lead to error when viewing digital video:
\begin{enumerate}
    \item Errors in the digital transmission path, meaning loss or picture and or audio.
    \item The video is compressed too much, leading to a noticeable quality loss.
\end{enumerate}


\section{DASH'ing}
Splitting up videos allows for easier \ac{IPFS} sharing. The file segmentation is important to enforce the flow of downloaded files through IPFS, due to a request queue of segments generated by the \ac{DASH} client.

This is possible due to the \ac{DASH} live profile, which support multiple files (segments) to form a stream. As a consequence of the segmentation each file should begin with an I Frame, which could mean that a video needs to be re-encoded to have enough "possible split-points".

Though \ac{DASH} is designed for multiple streams of different bit rate and a adaptive behaviour to maximize the quality of the downloaded content, this aspect won't be examined. Due to the back-end being \ac{P2P}, a single stream of video and audio is chosen to maximize availability of these files. As part of the hypothesis, it is also expected that a single high quality source on \ac{IPFS} can be served equally satisfactorily as several streams in a centralized setup.

\section{Multimedia Container \& Codecs}
\label{sec:video-encoding}
The chosen format for the stream is selected from the DASH-AVC/264 standard\cite{dash264}, due to its interoperability and because it's supported by the \texttt{dash.js} player.
The standard defines the multimedia container as MP4, the video codec as H.264 and the audio codec as AAC. As a addition separate audio and video streams are required, which means that multiplexing isn't allowed.



\section{Personas}
Possible user behaviours can be used in the experiment, they wary between collective and individual behaviours.\\
Collective behaviours affect the entire network and how the video is watched over time.
\subsection{Collective behaviours}
\begin{itemize}
    \item \textbf{Social:}
    Videos accessed through direct link (shared socially). Candidates for becoming viral, these videos tend to peak in views and then fall of drastically
    \item \textbf{Non-social:}
    Videos found through searching or related videos internally on site, these videos have more stable views over time in comparison to social.
\end{itemize}

\subsection{Individual behaviours}
\label{sec:individual-behavious}
Behaviours can also vary depending on the individual user. The following are possible kinds of users that could use the system.
\begin{itemize}
    \item \textbf{Seeder:}
    Is the user that is sharing content, either being the origin poster of said content or re-hosting it after having watched it themselves.
    \item \textbf{Leecher:}
    Is a user that tries to exploit the system, by minimizing the content shared with the other peers %use a different peer as gateway, maybe bootstrap
    \item \textbf{Binge:}
    Is a user that watches all content in chronological order
    \item \textbf{Skipper:}
    Is a user that watches many small segments of the video, by watching a small segment and then skipping forwards to watch another small segment.
    \item \textbf{Incognito:}
    Is a user only available in the network for a short time, watching a single video (or part of video) and deletes all of their content afterwards
    \item \textbf{Idle:}
    Is a user that is inside the network but does not actively interact with video content, and as such instead fulfills the roll of padding the other clients \acp{DHT}
\end{itemize}

\subsection{Viewing Conditions}
\label{sec:viewing-conmditions}
Behaviours can also vary depending on the network conditions of the user. The following are different conditions that could influence the usage.
\begin{itemize}
    \item \textbf{Mobile:}
    Unreliable due to fluctuating network connections and low bandwidth.
    \item \textbf{Remote:}
    High latency due to distance.
\end{itemize}


\section{Evaluation Experiments}
Experiments for measuring \ac{QOE}, meaning no re-buffering and stalls of streams;
\begin{itemize}
    \item \textbf{Bandwidth:}
    Both the upload and download speeds of the client can be manipulated, and at which point does these become to low to get a pleasant viewing experience, meaning that the video does not halt after it has initially started. Also how does the low upload affect the other peers, and what influence does fluctuating bandwidth capacity have such as that of a mobile client.
    \textit{Cases of eg. mobile devices.}
    \item \textbf{Churn rate:}
    What effect does clients leaving the network have on the video, and can videos partially or entirely disappear from the network, can a video be popular enough that this cannot reasonably occur. IT makes sense to see influence, due to the novelty of IPFS.
    \item \textbf{Segments availability:}
    How does the socialness and availability of the video impact the user experience and network. The socialness shows the availability over time, while very social videos also have sudden increases in viewership that suddenly drops off. Segments availability alone can be adjusted by the amount of seeders in the network and can be considered seperate from evaluating the impact of different levels of socialness.
    \item \textbf{Video Quality:}
    Influence of video resolution, \ac{FPS}, time between I-Frames and bit rate as the testing done by \citeauthor{aloman2015performance}.
    \item \textbf{Segments size:}
    How does different segment sizes affect the performance, it is expected that if it is too large, one does not properly load balance the requests but if it is too small, enough bytes are not given for the amount of traffic trying to locate the segment.
    \item \textbf{Buffer size:}
    Influence of changing \ac{DASH} player's preferred buffer size, meaning that less of the video can be stored in advance putting more pressure on the network for getting the individual segments fast, before the player stalls. %Done dynamically already, so maybe not that interesting. 
    \item \textbf{Public IPFS:}
    How does \ac{IPFS} perform in a small environment dedicated only to running the tests versus running the test in the global \ac{IPFS} network that is also used for other unrelated services.
    \textit{Case of "in the wild" performance.} 
    \item \textbf{Population behaviour:}
    How does the behaviour of the clients in the network affect the network and clients, both themselves and others, with different populations.
\end{itemize}
These tests are to be performed by setting up a \ac{P2P} network containing clients with \ac{IPFS} installed. Each client has a persona, and tests can be done with different populations of these personas.\\
%
%some kind of transition
%
Different percentages of users being seeders, a large amount of Seeders increases the availability of the video segments, without other clients have to get them themselves before others can.
Different percentages of users being Leechers, a large amount of Leechers is expected to put a high amount of stress on the network as the amount of peers that request files is dis disproportionally larger than the amount that can supply them.
Different percentages of users being idle, this pads the size of the network and can potentially fill up the hash tables of the active peers resulting in slower traffic.
Different kinds of user behaviours and how they impact the network compared to each other, this can be tested by having similar networks but the active video watching clients wary between them. The users where this would be relevant for are the Binge, Skipper and the Incognito personas. Between these users stalling is more tolerable on the Skipper and Incognito persona as they manually jump to a different point of the video and it is expected upon doing so the video will stall while the buffer is being filled with the relevant segments.
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../ClassicThesis"
%%% End:
